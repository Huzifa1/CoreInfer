{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e675d0-19cd-4af4-a06b-36b7cbfffee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'opt-6.7b' #'llama3-8b'\n",
    "checkpoint_path = '../models/opt-6.7b' #'../models/llama3-8b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316aff0-e31f-4f23-8da4-30e35fc60ae8",
   "metadata": {},
   "source": [
    "# Step1：Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3678b401-4c4d-4e0b-b22d-e84ae18995fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27af30e14694e4a85552f35a34b9016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import OPTForCausalLM,AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, device_map=device, torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, device_map=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e9d7b-7b2e-4d4d-8563-ab4f2e7749a3",
   "metadata": {},
   "source": [
    "# Step2：Core Neurons similarity evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "332ed6fb-6d18-4b82-98ff-19fdc8413b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model.cuda()\n",
    "token_sparsity = 0.2\n",
    "sparsity = 0.4\n",
    "\n",
    "\n",
    "def get_activation(name, activation_dict):\n",
    "    def hook(model, input, output):\n",
    "        activation_dict[name] = input[0].detach().cpu()\n",
    "    return hook\n",
    "\n",
    "\n",
    "def register_act_hooks(model, activation_dict):\n",
    "    hooks = []\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, torch.nn.ReLU):\n",
    "            hooks.append(layer.register_forward_hook(get_activation(name, activation_dict)))\n",
    "    return hooks\n",
    "\n",
    "\n",
    "def remove_hooks(hooks):\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "\n",
    "def activation_opt_similarity(sentence1,sentence2):\n",
    "    data = [sentence1,sentence2]\n",
    "    activations = []\n",
    "    for i in range(len(data)):\n",
    "        prompt = data[i]\n",
    "        \n",
    "        cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,!?;:]', '', prompt)\n",
    "        tokenized_input = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=256, truncation=True).to(device)\n",
    "        \n",
    "        activation_dict = {}\n",
    "        hooks = register_act_hooks(model, activation_dict)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_input)\n",
    "        \n",
    "        activations.append(activation_dict)\n",
    "        remove_hooks(hooks)\n",
    "        \n",
    "        del outputs\n",
    "        del tokenized_input\n",
    "        del activation_dict\n",
    "\n",
    "    Layer_num = 25\n",
    "\n",
    "    layer_act=[]\n",
    "    sentence_lenth=[]\n",
    "    for i in range(len(activations)):\n",
    "        str_act=\"model.decoder.layers.\"+str(Layer_num)+\".activation_fn\"\n",
    "        tensor = activations[i][str_act].cpu()\n",
    "        layer_act.append(tensor)\n",
    "        m=tensor.size(0)\n",
    "        sentence_lenth.append(m)\n",
    "    A_tensor = torch.cat(layer_act, dim=0)\n",
    "    tensorA=torch.sign(A_tensor)\n",
    "    sentence=[]\n",
    "    \n",
    "    num=0\n",
    "    for i in range(len(sentence_lenth)):\n",
    "        lenth=sentence_lenth[i]\n",
    "        list_now=list(range(num, num+lenth))\n",
    "        sentence.append(list_now)\n",
    "        num=num+lenth\n",
    "    \n",
    "    act_all=(A_tensor).cpu()\n",
    "    count_act_all = (act_all > 0).sum(dim=1)\n",
    "    sorted_values, sorted_indices = torch.sort(act_all, dim=1, descending=True)\n",
    "    \n",
    "    top50_indices=[]\n",
    "    for i in range(act_all.size(0)):\n",
    "        indices = sorted_indices[i, :int(torch.round(count_act_all[i]*token_sparsity))]\n",
    "        top50_indices.append(indices.tolist())\n",
    "    \n",
    "    SEN_F=[]\n",
    "    for i in range(len(sentence)):\n",
    "        cluster5= sentence[i]\n",
    "        act_clu =  [top50_indices[i] for i in cluster5]\n",
    "        data_flattened = [item for sublist in act_clu for item in sublist]\n",
    "        data_flattened=torch.tensor(data_flattened)\n",
    "        unique_numbers, counts = data_flattened.unique(return_counts=True, sorted=True)\n",
    "    \n",
    "        sorted_indices = torch.argsort(counts, descending=True)\n",
    "        sorted_numbers = unique_numbers[sorted_indices]\n",
    "        sorted_counts = counts[sorted_indices]\n",
    "        neurons_remained = int(sparsity * len(sorted_numbers))\n",
    "        SEN_F.append(sorted_numbers[:neurons_remained].numpy())\n",
    "\n",
    "    similarity=len(np.intersect1d(SEN_F[0], SEN_F[1]))/len(SEN_F[1])\n",
    "    return similarity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95296501-7f43-4578-8360-c17f97d302b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model.cuda()\n",
    "token_sparsity = 0.2\n",
    "sparsity = 0.4\n",
    "\n",
    "def get_activation(name, activation_dict):\n",
    "    def hook(model, input, output):\n",
    "        activation_dict[name] = input[0].detach().cpu()\n",
    "    return hook\n",
    "\n",
    "\n",
    "def register_act_hooks(model, activation_dict):\n",
    "    hooks = []\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, torch.nn.SiLU):\n",
    "            hooks.append(layer.register_forward_hook(get_activation(name, activation_dict)))\n",
    "    return hooks\n",
    "\n",
    "\n",
    "def remove_hooks(hooks):\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "\n",
    "def activation_llama_similarity(sentence1,sentence2):\n",
    "    data = [sentence1,sentence2]\n",
    "    activations = []\n",
    "    for i in range(len(data)):\n",
    "        prompt = data[i]\n",
    "        tokenized_input = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        activation_dict = {}\n",
    "        hooks = register_act_hooks(model, activation_dict)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_input)\n",
    "        \n",
    "        activations.append(activation_dict)\n",
    "        remove_hooks(hooks)\n",
    "        \n",
    "        del outputs\n",
    "        del tokenized_input\n",
    "        del activation_dict\n",
    "\n",
    "    Layer_num = 70\n",
    "\n",
    "    layer_act=[]\n",
    "    sentence_lenth=[]\n",
    "    for i in range(len(activations)):\n",
    "        str_act=\"model.layers.\"+str(Layer_num)+\".mlp.act_fn\"\n",
    "        tensor = activations[i][str_act].cpu()\n",
    "        layer_act.append(tensor.squeeze(0))\n",
    "        m=tensor.size(1)\n",
    "        sentence_lenth.append(m)\n",
    "    A_tensor = torch.cat(layer_act, dim=0)\n",
    "    tensorA=torch.sign(A_tensor)\n",
    "    sentence=[]\n",
    "    \n",
    "    num=0\n",
    "    for i in range(len(sentence_lenth)):\n",
    "        lenth=sentence_lenth[i]\n",
    "        list_now=list(range(num, num+lenth))\n",
    "        sentence.append(list_now)\n",
    "        num=num+lenth\n",
    "    \n",
    "    act_all=(A_tensor).cpu()\n",
    "    count_act_all = (act_all > 0).sum(dim=1)\n",
    "    sorted_values, sorted_indices = torch.sort(act_all, dim=1, descending=True)\n",
    "    \n",
    "    top50_indices=[]\n",
    "    for i in range(act_all.size(0)):\n",
    "        indices = sorted_indices[i, :int(torch.round(count_act_all[i]*token_sparsity))]\n",
    "        top50_indices.append(indices.tolist())\n",
    "    \n",
    "    SEN_F=[]\n",
    "    for i in range(len(sentence)):\n",
    "        cluster5= sentence[i]\n",
    "        act_clu =  [top50_indices[i] for i in cluster5]\n",
    "        data_flattened = [item for sublist in act_clu for item in sublist]\n",
    "        data_flattened=torch.tensor(data_flattened)\n",
    "        unique_numbers, counts = data_flattened.unique(return_counts=True, sorted=True)\n",
    "    \n",
    "        sorted_indices = torch.argsort(counts, descending=True)\n",
    "        sorted_numbers = unique_numbers[sorted_indices]\n",
    "        sorted_counts = counts[sorted_indices]\n",
    "        neurons_remained = int(sparsity * len(sorted_numbers))\n",
    "        SEN_F.append(sorted_numbers[:neurons_remained].numpy())\n",
    "\n",
    "    similarity=len(np.intersect1d(SEN_F[0], SEN_F[1]))/len(SEN_F[1])\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce928b5b-9d88-4772-93c0-3c75c2a5024a",
   "metadata": {},
   "source": [
    "# Step4: Pearson Correlation Coefficient on STS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "654c1992-e47e-414c-8e0a-6ccac112161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['split', 'genre', 'dataset', 'year', 'sid', 'score', 'sentence1', 'sentence2'],\n",
      "        num_rows: 5749\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['split', 'genre', 'dataset', 'year', 'sid', 'score', 'sentence1', 'sentence2'],\n",
      "        num_rows: 1500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['split', 'genre', 'dataset', 'year', 'sid', 'score', 'sentence1', 'sentence2'],\n",
      "        num_rows: 1379\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset( 'mteb/stsbenchmark-sts')\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74eb8510-c901-4dbc-9034-b6d352a60dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_all=[]\n",
    "true_all=[]\n",
    "data=dataset['validation']\n",
    "\n",
    "for i in range(len(data)):\n",
    "    sentence1 = dataset['validation'][i]['sentence1']\n",
    "    sentence2 = dataset['validation'][i]['sentence2']\n",
    "    if \"opt\" in model_name:\n",
    "        act_sim=activation_opt_similarity(sentence1,sentence2)\n",
    "    elif \"llama\" in model_name:\n",
    "        act_sim=activation_llama_similarity(sentence1,sentence2)\n",
    "    true_sim=dataset['validation'][i]['score']\n",
    "    sim_all.append(act_sim)\n",
    "    true_all.append(true_sim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a299db3-220f-45a0-b3a4-6751ab20b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.5874475337292442\n",
      "P-value: 7.283538395503928e-140\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "correlation, p_value = spearmanr(sim_all, true_all)\n",
    "print(f\"Spearman correlation: {correlation}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb91d7b-4932-491b-82c5-4a9578435e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a14c4-93e4-4394-b3e9-268ed80fb10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd70ac3-94b9-4073-8364-a7ab1ef08c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a06d1178-47e7-4068-96db-a544447fbd25",
   "metadata": {},
   "source": [
    "# Step4: Pearson Correlation Coefficient on Sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1bd8da-4faa-4016-b357-d407be46e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['pair_ID', 'sentence_A', 'sentence_B', 'entailment_label', 'relatedness_score', 'entailment_AB', 'entailment_BA', 'sentence_A_original', 'sentence_B_original', 'sentence_A_dataset', 'sentence_B_dataset', 'SemEval_set', 'label', 'label_seq2seq'],\n",
      "        num_rows: 4439\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['pair_ID', 'sentence_A', 'sentence_B', 'entailment_label', 'relatedness_score', 'entailment_AB', 'entailment_BA', 'sentence_A_original', 'sentence_B_original', 'sentence_A_dataset', 'sentence_B_dataset', 'SemEval_set', 'label', 'label_seq2seq'],\n",
      "        num_rows: 495\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['pair_ID', 'sentence_A', 'sentence_B', 'entailment_label', 'relatedness_score', 'entailment_AB', 'entailment_BA', 'sentence_A_original', 'sentence_B_original', 'sentence_A_dataset', 'sentence_B_dataset', 'SemEval_set', 'label', 'label_seq2seq'],\n",
      "        num_rows: 4906\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset( 'maximedb/sick_nl')\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b15c42-df99-4ebe-a5ca-1ff3cca7cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_all=[]\n",
    "true_all=[]\n",
    "data=dataset['validation']\n",
    "\n",
    "for i in range(len(data)):\n",
    "    sentence1 = dataset['validation'][i]['sentence_A']\n",
    "    sentence2 = dataset['validation'][i]['sentence_B']\n",
    "    if \"opt\" in model_name:\n",
    "        act_sim=activation_opt_similarity(sentence1,sentence2)\n",
    "    elif \"llama\" in model_name:\n",
    "        act_sim=activation_llama_similarity(sentence1,sentence2)\n",
    "    true_sim=dataset['validation'][i]['relatedness_score']\n",
    "    sim_all.append(act_sim)\n",
    "    true_all.append(true_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dccd90f-e929-4be5-b281-14269c584839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.3683946806722181\n",
      "P-value: 2.3418180334252915e-17\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "correlation, p_value = spearmanr(sim_all, true_all)\n",
    "print(f\"Spearman correlation: {correlation}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d2bd5-edd3-4140-ae88-adaa72f9ed3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

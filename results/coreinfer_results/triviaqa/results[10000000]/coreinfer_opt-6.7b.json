{"triviaqa": {"alias": "triviaqa", "exact_match,remove_whitespace": 0.2888987962550156, "exact_match_stderr,remove_whitespace": 0.003383693713292116}, "command": "Command: evaluate_task.py --model_name opt-6.7b --checkpoint_path /local/huzaifa/workspace/models/opt-6.7b/ --limit 10000000 --task_name triviaqa --output_path /local/huzaifa/workspace/CoreInfer/stable_guided_results/triviaqa/results[10000000]/coreinfer_opt-6.7b.json --token_sparsity 0.2 --sparsity 0.4 --method stable_guided --start_num 4 --end_num 26"}
{"mlqa_en_en": {"alias": "mlqa_en_en", "exact_match,none": 0.5255392579810181, "exact_match_stderr,none": 0.004638523297119906, "f1,none": 0.6908321673038246, "f1_stderr,none": 0.003644484228835713}, "command": "Command: evaluate_task.py --model_name llama3-3b --checkpoint_path /local/huzaifa/workspace/models/llama3-3b/ --limit 10000000 --task_name mlqa_en_en --output_path /local/huzaifa/CoreInfer/results/stable_guided_results/mlqa_en_en/results[10000000]/coreinfer_llama3-3b.json --token_sparsity 0.2 --sparsity 0.4 --method stable_guided --start_num 4 --end_num 26"}